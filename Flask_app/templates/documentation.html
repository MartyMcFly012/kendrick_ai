<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Project Documentation</title>
    <!-- Bootstrap 5 CSS link -->
    <link
      href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css"
      rel="stylesheet" />
    <!-- Add any additional styling or meta tags if needed -->
    <style>
      /* Add your custom CSS styles here */
    </style>
  </head>

  <body class="bg-dark text-light">
    <div class="container">
      <h1>Project Documentation</h1>

      <h2>Project Overview</h2>
      <p>
        This project initially started as part of the Music, Mind, and the Brain
        class I took while in College. The goal was to model human-like musical
        capabilities with machine learning. I chose Kendrick Lamar, a prominent
        rap artist, as the subject to explore the possibility of training a
        model to generate lyrics in his style. While the models presented here
        may not replace Kendrick, given the relatively small training data, it's
        impressive how well the model learns to rhyme without direct
        instruction.
      </p>

      <h2>Choice of Bidirectional LSTM</h2>
      <p>
        The choice of a bidirectional LSTM was made to consider context during
        training. While a traditional LSTM captures context only forward, a
        bidirectional LSTM works both forwards and backwards. This enables the
        model to reason and make more informed predictions.
      </p>

      <h2>Findings</h2>
      <p>
        The model showed a sweet spot around 20 epochs. Occasionally, it
        generated coherent and Kendrick-like text. During hyperparameter tuning,
        fitting the model for 50 epochs resulted in text getting stuck on
        certain words. This phenomenon was also observed when using too many
        bidirectional LSTM layers. While the generated text is generally
        incoherent, a larger dataset might improve readability.
      </p>

      <h2>Conclusion</h2>
      <p>
        Bidirectional LSTMs excel in capturing complex features in song lyrics,
        evident in their ability to generate rhyming lyrics based on a raw text
        file. Future research could explore the addition of regular LSTMs for
        comparison in this task. Another possibility is exploring the
        transformer architecture and implementing attention.
      </p>

      <h2>References</h2>
      <ul>
        <li>
          Citations: Retrieved data from kendrick.txt at
          <a href="https://github.com/YigitGunduc/Spectrum"
            >https://github.com/YigitGunduc/Spectrum</a
          >
        </li>
      </ul>

      <hr />

      <a href="/" class="btn btn-primary">Back to Home</a>
    </div>

    <!-- Bootstrap 5 JS bundle -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
    <!-- Add any additional JavaScript if needed -->
    <script>
      // Add your custom JavaScript code here
    </script>
  </body>
</html>
